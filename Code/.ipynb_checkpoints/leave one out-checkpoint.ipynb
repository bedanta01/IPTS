{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import codecs\n",
    "from collections import Counter,defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_dataframe = pd.read_csv(\"../data/Labelled_tweets_v1.csv\",header = None)\n",
    "tweets = []\n",
    "data_pd = pd.read_csv(\"../data/Labelled_tweets_v1.csv\")\n",
    "#print(data_pd.head(10))\n",
    "data_tweet = data_pd['Tweet']\n",
    "for i in data_tweet:\n",
    "  j = i.split()\n",
    "  for k in j:\n",
    "    tweets.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_pd = data_pd['Issue']\n",
    "stance_pd = data_pd['Stance']\n",
    "\n",
    "all_words = tweets\n",
    "word2cnt = Counter(all_words)\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('vocab_real.csv', 'w', 'utf-8') as fout:\n",
    "  fout.write(\"{}{}1000000000\\n{}{}1000000000\\n{}{}1000000000\\n{}{}1000000000\\n\".format(\"<PAD>\",\",\", \"<UNK>\",\",\", \"<S>\",\",\", \"</S>\",\",\"))\n",
    "  for word, cnt in word2cnt.most_common(len(word2cnt)):\n",
    "    if(word not in stop_words):\n",
    "      fout.write(\"{}{}{} \\n\".format(word,',',cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GST', 'PNB Scam', 'FDIPolicy', 'Padmavati film screening', 'Cauvery SC Verdict', 'Jallikattu ban', 'GDP growth', 'RightToPrivacy SC Verdict', 'Demonetisation', 'Swacch Bharat', 'Aadhar linking', 'Triple Talaq SC verdict', 'TripleTalaqBill', 'lgp price hike', 'reservation', 'Beef Ban', 'Inflation control', 'nsc and ppf rate cuts', 'Ram Mandir', 'EVM tampering', 'Fodder scam', 'hike in oil prices', 'Rohingyas', 'acchedin']\n",
      "[['a no of people approach me daily worried abt the safety of their money in banks considering large no of bank frauds coming to light daily pm may kindly inform the public which bank is safe for people to keep their money URL sir there is a big rumour people are very skeptical that their saved money in the banks can go for a toss anytime hope wish pray that you our people all of us save the hard earned money in banks improve our incomes strengthen the income tax system'\n",
      "  'ArvindKejriwal' 'AAP' 'GST' 'Disagreement']\n",
      " ['its now revealed that our fms silence on the pnb scam was to protect his lawyer daughter who was paid a large retainer by the accused just a month before the scam became public when other law firms of the accused have been raided by the cbi why not hers modirobsindia URL you know doing something right when the ruling dispensation tries to rebut a story that has not even been published yet URL'\n",
      "  'ArvindKejriwal' 'AAP' 'PNB Scam' 'Neutral']\n",
      " ['pnb scam started in is going on till today the bjp is accusing the cong and cong bjp is also on the side of cong pnb scam started in is going on till today the bjp is accusing the cong and cong bjp is the only one that all the scams of cong time are still going on earlier cong was earning now the bjp earns from those scams that is why till today the bjp has not sent a single congressman to jail in any scam'\n",
      "  'ArvindKejriwal' 'AAP' 'PNB Scam' 'Neutral']\n",
      " ['would bjp confirm this if true what transpired in that meeting breaking my sources tell me that niravmodi his brother had a privileged private meeting with USER_MENTION in davos'\n",
      "  'ArvindKejriwal' 'AAP' 'PNB Scam' 'Neutral']\n",
      " ['bjp insiders telling that niravmodi been a regular donor to the party coffers since modi was cm that is primarily the reason behind his closer proximity to pmo why pm decided to look the other way it is just not a bank fraud but has all the ingrediants of a massive scam URL breaking cnnnews18 has accessed complainant letter to pmo on nirav modi complainant received acknowledgment from pmo over letter in USER_MENTION with details bigbankscam'\n",
      "  'ArvindKejriwal' 'AAP' 'PNB Scam' 'Neutral']]\n"
     ]
    }
   ],
   "source": [
    "issues = []\n",
    "for iss in issues_pd:\n",
    "  if iss not in issues:\n",
    "    issues.append(iss)\n",
    "    \n",
    "print(issues)\n",
    "\n",
    "word_counts = pd.read_csv(\"vocab_real.csv\",header=None)\n",
    "data_list = data_pd.values\n",
    "print(data_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'no', 'of', 'people', 'approach', 'me', 'daily', 'worried', 'abt', 'the', 'safety', 'of', 'their', 'money', 'in', 'banks', 'considering', 'large', 'no', 'of', 'bank', 'frauds', 'coming', 'to', 'light', 'daily', 'pm', 'may', 'kindly', 'inform', 'the', 'public', 'which', 'bank', 'is', 'safe', 'for', 'people', 'to', 'keep', 'their', 'money', 'URL', 'sir', 'there', 'is', 'a', 'big', 'rumour', 'people', 'are', 'very', 'skeptical', 'that', 'their', 'saved', 'money', 'in', 'the', 'banks', 'can', 'go', 'for', 'a', 'toss', 'anytime', 'hope', 'wish', 'pray', 'that', 'you', 'our', 'people', 'all', 'of', 'us', 'save', 'the', 'hard', 'earned', 'money', 'in', 'banks', 'improve', 'our', 'incomes', 'strengthen', 'the', 'income', 'tax', 'system'], ['its', 'now', 'revealed', 'that', 'our', 'fms', 'silence', 'on', 'the', 'pnb', 'scam', 'was', 'to', 'protect', 'his', 'lawyer', 'daughter', 'who', 'was', 'paid', 'a', 'large', 'retainer', 'by', 'the', 'accused', 'just', 'a', 'month', 'before', 'the', 'scam', 'became', 'public', 'when', 'other', 'law', 'firms', 'of', 'the', 'accused', 'have', 'been', 'raided', 'by', 'the', 'cbi', 'why', 'not', 'hers', 'modirobsindia', 'URL', 'you', 'know', 'doing', 'something', 'right', 'when', 'the', 'ruling', 'dispensation', 'tries', 'to', 'rebut', 'a', 'story', 'that', 'has', 'not', 'even', 'been', 'published', 'yet', 'URL'], ['pnb', 'scam', 'started', 'in', 'is', 'going', 'on', 'till', 'today', 'the', 'bjp', 'is', 'accusing', 'the', 'cong', 'and', 'cong', 'bjp', 'is', 'also', 'on', 'the', 'side', 'of', 'cong', 'pnb', 'scam', 'started', 'in', 'is', 'going', 'on', 'till', 'today', 'the', 'bjp', 'is', 'accusing', 'the', 'cong', 'and', 'cong', 'bjp', 'is', 'the', 'only', 'one', 'that', 'all', 'the', 'scams', 'of', 'cong', 'time', 'are', 'still', 'going', 'on', 'earlier', 'cong', 'was', 'earning', 'now', 'the', 'bjp', 'earns', 'from', 'those', 'scams', 'that', 'is', 'why', 'till', 'today', 'the', 'bjp', 'has', 'not', 'sent', 'a', 'single', 'congressman', 'to', 'jail', 'in', 'any', 'scam'], ['would', 'bjp', 'confirm', 'this', 'if', 'true', 'what', 'transpired', 'in', 'that', 'meeting', 'breaking', 'my', 'sources', 'tell', 'me', 'that', 'niravmodi', 'his', 'brother', 'had', 'a', 'privileged', 'private', 'meeting', 'with', 'USER_MENTION', 'in', 'davos'], ['bjp', 'insiders', 'telling', 'that', 'niravmodi', 'been', 'a', 'regular', 'donor', 'to', 'the', 'party', 'coffers', 'since', 'modi', 'was', 'cm', 'that', 'is', 'primarily', 'the', 'reason', 'behind', 'his', 'closer', 'proximity', 'to', 'pmo', 'why', 'pm', 'decided', 'to', 'look', 'the', 'other', 'way', 'it', 'is', 'just', 'not', 'a', 'bank', 'fraud', 'but', 'has', 'all', 'the', 'ingrediants', 'of', 'a', 'massive', 'scam', 'URL', 'breaking', 'cnnnews18', 'has', 'accessed', 'complainant', 'letter', 'to', 'pmo', 'on', 'nirav', 'modi', 'complainant', 'received', 'acknowledgment', 'from', 'pmo', 'over', 'letter', 'in', 'USER_MENTION', 'with', 'details', 'bigbankscam']]\n"
     ]
    }
   ],
   "source": [
    "#data_tweet = data_tweet.values.tolist()\n",
    "# for i in range(0,len(data_tweet)):\n",
    "#     data_tweet[i] = data_tweet[i].split()\n",
    "    \n",
    "print(data_tweet[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = stopwords.words('english') + list(string.punctuation) + ['will', 'also', 'said','a','URL','USER_MENTION']\n",
    "tweets_after_stop_words=[]\n",
    "for i in data_tweet:\n",
    "    tweet = []\n",
    "    for j in i:\n",
    "        if(j not in stopset):\n",
    "            tweet.append(j)\n",
    "    tweets_after_stop_words.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wv = Word2Vec(data_tweet,min_count=0,window=5,size=100)\n",
    "#len(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bedanta/ml/lib/python3.5/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "tweet_vectors =[]\n",
    "for i in range(0,len(tweets_after_stop_words)):\n",
    "    tweet_vectors.append(model_wv[tweets_after_stop_words[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['people',\n",
       "  'approach',\n",
       "  'daily',\n",
       "  'worried',\n",
       "  'abt',\n",
       "  'safety',\n",
       "  'money',\n",
       "  'banks',\n",
       "  'considering',\n",
       "  'large',\n",
       "  'bank',\n",
       "  'frauds',\n",
       "  'coming',\n",
       "  'light',\n",
       "  'daily',\n",
       "  'pm',\n",
       "  'may',\n",
       "  'kindly',\n",
       "  'inform',\n",
       "  'public',\n",
       "  'bank',\n",
       "  'safe',\n",
       "  'people',\n",
       "  'keep',\n",
       "  'money',\n",
       "  'sir',\n",
       "  'big',\n",
       "  'rumour',\n",
       "  'people',\n",
       "  'skeptical',\n",
       "  'saved',\n",
       "  'money',\n",
       "  'banks',\n",
       "  'go',\n",
       "  'toss',\n",
       "  'anytime',\n",
       "  'hope',\n",
       "  'wish',\n",
       "  'pray',\n",
       "  'people',\n",
       "  'us',\n",
       "  'save',\n",
       "  'hard',\n",
       "  'earned',\n",
       "  'money',\n",
       "  'banks',\n",
       "  'improve',\n",
       "  'incomes',\n",
       "  'strengthen',\n",
       "  'income',\n",
       "  'tax',\n",
       "  'system'],\n",
       " ['revealed',\n",
       "  'fms',\n",
       "  'silence',\n",
       "  'pnb',\n",
       "  'scam',\n",
       "  'protect',\n",
       "  'lawyer',\n",
       "  'daughter',\n",
       "  'paid',\n",
       "  'large',\n",
       "  'retainer',\n",
       "  'accused',\n",
       "  'month',\n",
       "  'scam',\n",
       "  'became',\n",
       "  'public',\n",
       "  'law',\n",
       "  'firms',\n",
       "  'accused',\n",
       "  'raided',\n",
       "  'cbi',\n",
       "  'modirobsindia',\n",
       "  'know',\n",
       "  'something',\n",
       "  'right',\n",
       "  'ruling',\n",
       "  'dispensation',\n",
       "  'tries',\n",
       "  'rebut',\n",
       "  'story',\n",
       "  'even',\n",
       "  'published',\n",
       "  'yet'],\n",
       " ['pnb',\n",
       "  'scam',\n",
       "  'started',\n",
       "  'going',\n",
       "  'till',\n",
       "  'today',\n",
       "  'bjp',\n",
       "  'accusing',\n",
       "  'cong',\n",
       "  'cong',\n",
       "  'bjp',\n",
       "  'side',\n",
       "  'cong',\n",
       "  'pnb',\n",
       "  'scam',\n",
       "  'started',\n",
       "  'going',\n",
       "  'till',\n",
       "  'today',\n",
       "  'bjp',\n",
       "  'accusing',\n",
       "  'cong',\n",
       "  'cong',\n",
       "  'bjp',\n",
       "  'one',\n",
       "  'scams',\n",
       "  'cong',\n",
       "  'time',\n",
       "  'still',\n",
       "  'going',\n",
       "  'earlier',\n",
       "  'cong',\n",
       "  'earning',\n",
       "  'bjp',\n",
       "  'earns',\n",
       "  'scams',\n",
       "  'till',\n",
       "  'today',\n",
       "  'bjp',\n",
       "  'sent',\n",
       "  'single',\n",
       "  'congressman',\n",
       "  'jail',\n",
       "  'scam'],\n",
       " ['would',\n",
       "  'bjp',\n",
       "  'confirm',\n",
       "  'true',\n",
       "  'transpired',\n",
       "  'meeting',\n",
       "  'breaking',\n",
       "  'sources',\n",
       "  'tell',\n",
       "  'niravmodi',\n",
       "  'brother',\n",
       "  'privileged',\n",
       "  'private',\n",
       "  'meeting',\n",
       "  'davos'],\n",
       " ['bjp',\n",
       "  'insiders',\n",
       "  'telling',\n",
       "  'niravmodi',\n",
       "  'regular',\n",
       "  'donor',\n",
       "  'party',\n",
       "  'coffers',\n",
       "  'since',\n",
       "  'modi',\n",
       "  'cm',\n",
       "  'primarily',\n",
       "  'reason',\n",
       "  'behind',\n",
       "  'closer',\n",
       "  'proximity',\n",
       "  'pmo',\n",
       "  'pm',\n",
       "  'decided',\n",
       "  'look',\n",
       "  'way',\n",
       "  'bank',\n",
       "  'fraud',\n",
       "  'ingrediants',\n",
       "  'massive',\n",
       "  'scam',\n",
       "  'breaking',\n",
       "  'cnnnews18',\n",
       "  'accessed',\n",
       "  'complainant',\n",
       "  'letter',\n",
       "  'pmo',\n",
       "  'nirav',\n",
       "  'modi',\n",
       "  'complainant',\n",
       "  'received',\n",
       "  'acknowledgment',\n",
       "  'pmo',\n",
       "  'letter',\n",
       "  'details',\n",
       "  'bigbankscam']]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tweets_after_stop_words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,vocab_size, hidden_size,input_size):\n",
    "        super(Net,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        #self.word_embeddings = nn.Embedding(vocab_size+106, self.hidden_size)\n",
    "        self.GRU = nn.GRU(self.input_size,self.hidden_size, batch_first = True)\n",
    "        self.linear = nn.Linear(self.hidden_size, 3)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self,x_input,hidden_state):\n",
    "        #embedded = self.word_embeddings(x_input)\n",
    "        #output = embedded#.view(-1,-1, self.hidden_size)\n",
    "        output, hn = self.GRU(x_input,hidden_state)\n",
    "        linear = self.linear(hn)\n",
    "        #print(linear.shape)\n",
    "        class_labels = self.softmax(linear)\n",
    "        \n",
    "        return class_labels\n",
    "\n",
    "    def H_t0(self, batch_size):\n",
    "        return torch.zeros(1,batch_size,self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issue_vocab(issues,want = 'issue2id'):\n",
    "    if(want == 'issue2id'):\n",
    "        issue2idx = {issue:idx for idx,issue in enumerate(issues)}\n",
    "        return issue2idx\n",
    "    \n",
    "    else:\n",
    "        idx2issue = {idx:issue for idx,issue in enumerate(issues)}\n",
    "        return idx2issue\n",
    "    \n",
    "def sent_vocab(want = 'sent2id'):\n",
    "    sent2id = {'Disagreement':0,'Neutral':1,'Agreement':2}\n",
    "    id2sent = {0:'Disagreement',1:'Neutral',2:'Agreement'}\n",
    "    if(want == 'sent2id'):\n",
    "        return sent2id\n",
    "\n",
    "    else:\n",
    "        #idx2issue = {idx:issue for idx,issue in enumerate(issues)}\n",
    "        return idx2sent\n",
    "\n",
    "def load_vocab():\n",
    "    load_words = open(\"vocab_real.csv\").readlines()\n",
    "    for i in range(len(load_words)):\n",
    "        load_words[i] = load_words[i].split(',')\n",
    "    vocab = [load_words[i][0] for i in range(len(load_words))]\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    idx2word = {idx: word for idx, word in enumerate(vocab)}\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(tweets, issue_, sentiments,issues):\n",
    "    #print(len(tweets))\n",
    "    stop_words = ['the','of','in','and','a','is','on','this','all','it','will','for','to','be','with',\n",
    "              'at','are','u','has','that','by','from', 'as','was','have','its','an','if','been','be','also','should','which']\n",
    "    max_tweet_size = 65\n",
    "    word2idx,idx2word = load_vocab()\n",
    "    issue2idx = issue_vocab(issues,'issue2id')\n",
    "    sent2idx = sent_vocab()\n",
    "\n",
    "    x_tweet, y_issue, y_label = [], [], []\n",
    "    for tweet,issue,sent in zip(tweets, issue_, sentiments):\n",
    "        x = [word2idx.get(word, 1) for word in (tweet + u\" </S>\").split() if word not in stop_words]\n",
    "        x = np.array(x)\n",
    "        t = np.zeros(max_tweet_size)\n",
    "        if len(x)<=max_tweet_size:\n",
    "            t[:len(x)] = x\n",
    "        else:\n",
    "            t = x[:max_tweet_size]\n",
    "\n",
    "        #print(issue)\n",
    "        y_i = [issue2idx.get(issue,1)]\n",
    "        y_l = [sent2idx.get(sent,1)]\n",
    "\n",
    "        x_tweet.append(t)\n",
    "        y_issue.append(y_i)\n",
    "        y_label.append(y_l)\n",
    "    #print(len(x_tweet))\n",
    "    return np.array(x_tweet), np.array(y_issue), np.array(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches_train(data_x,data_y,batch_size, idx):\n",
    "    start =  batch_size*idx\n",
    "    end = start + batch_size\n",
    "    if(end>len(data_x)):\n",
    "        return data_x[start:], data_y[start:]\n",
    "    return data_x[start:end], data_y[start:end]\n",
    "\n",
    "def batches_test(data_x,data_y,batch_size, idx):\n",
    "    start =  batch_size*idx\n",
    "    end = start + batch_size\n",
    "    return data_x[start:end], data_y[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_issues = 24#len(issues)\n",
    "epochs = 10\n",
    "input_size = 256\n",
    "vocab_size = len(word_counts)\n",
    "output_size_issue = num_issues\n",
    "output_size_label = 3\n",
    "hidden_size = 256\n",
    "batch_size = 32 \n",
    "#n_iters = int(len(x_train)/batch_size)\n",
    "lr = 0.01\n",
    "\n",
    "num_issues = len(issues_pd.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss_all_issues = defaultdict(list)\n",
    "metrics_dict = defaultdict(list)\n",
    "predicted_list = defaultdict(list)\n",
    "ground_truth = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_wv(tweets, issue_, sentiments,issues):\n",
    "    stop_words = ['the','of','in','and','a','is','on','this','all','it','will','for','to','be','with',\n",
    "              'at','are','u','has','that','by','from', 'as','was','have','its','an','if','been','be','also','should','which']\n",
    "    #print(tweets[0])\n",
    "    leng = 0\n",
    "    for i in tweets:\n",
    "        len_ = len(i.split())\n",
    "        if(len_ > leng):\n",
    "            leng = len_\n",
    "    \n",
    "    max_tweet_size = leng\n",
    "    word2idx,idx2word = load_vocab()\n",
    "    issue2idx = issue_vocab(issues,'issue2id')\n",
    "    sent2idx = sent_vocab()\n",
    "    tweets_train=[]\n",
    "        \n",
    "\n",
    "    x_tweet, y_issue, y_label = [], [], []\n",
    "    for tweet,issue,sent in zip(tweets, issue_, sentiments):\n",
    "        x = [model_wv[word] for word in tweet.split() if word not in stop_words]\n",
    "        t = np.zeros([max_tweet_size,100])\n",
    "        if len(x)<=max_tweet_size:\n",
    "            t[:len(x)] = x\n",
    "        else:\n",
    "            t = x[:max_tweet_size]\n",
    "\n",
    "        y_i = [issue2idx.get(issue,1)]\n",
    "        y_l = [sent2idx.get(sent,1)]\n",
    "\n",
    "        x_tweet.append(t)\n",
    "        y_issue.append(y_i)\n",
    "        y_label.append(y_l)\n",
    "        \n",
    "    return np.array(x_tweet), np.array(y_issue), np.array(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bedanta/ml/lib/python3.5/site-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/bedanta/ml/lib/python3.5/site-packages/ipykernel_launcher.py:47: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.FloatTensor but found type torch.LongTensor for argument #4 'mat1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-b18928760810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mencoder_hidden_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH_t0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tweet_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mpredicted_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tweet_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_hidden_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mpredicted_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tweet_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mpredicted_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-160-5e9d1f341fb7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_input, hidden_state)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#embedded = self.word_embeddings(x_input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#output = embedded#.view(-1,-1, self.hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mlinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#print(linear.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mb_ih\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mi_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.FloatTensor but found type torch.LongTensor for argument #4 'mat1'"
     ]
    }
   ],
   "source": [
    "for one in issues:\n",
    "    net = Net(vocab_size, hidden_size,100)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "    \n",
    "    \n",
    "    if(one == '0'):\n",
    "        continue\n",
    "    data_withot_one_issue = data_pd[data_pd.Issue != one]\n",
    "    data_with_the_issue = data_pd[data_pd.Issue == one]\n",
    "    \n",
    "    data_list_with = data_withot_one_issue.values\n",
    "    data_list_without = data_with_the_issue.values\n",
    "    \n",
    "    tweets_train = data_list_with[:,0]\n",
    "    #print(tweets_train[0])\n",
    "    issue_train = data_list_with[:,3]\n",
    "    label_train = data_list_with[:,4]\n",
    "    tweets_test = data_list_without[:,0]\n",
    "    issue_test = data_list_without[:,3]\n",
    "    label_test = data_list_without[:,4]\n",
    "    \n",
    "    x_tweet_train,y_issue_train, y_label_train = create_data_wv(tweets_train,issue_train,label_train,issues)\n",
    "    #print(x_tweet_train[0])\n",
    "    x_tweet_test,y_issue_test, y_label_test = create_data_wv(tweets_test,issue_test,label_test,issues)\n",
    "    x_tweet_test, y_label_test = Variable(torch.FloatTensor(x_tweet_test)), Variable(torch.LongTensor(y_label_test))\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    epoch_losses = []\n",
    "    for e in range(0,10):\n",
    "        epoch_loss = 0\n",
    "        for idx in range(0,int(len(x_tweet_train)/batch_size)+1):\n",
    "            optimizer.zero_grad()\n",
    "            batch_x, batch_y = batches_train(x_tweet_train,y_label_train,batch_size,idx)\n",
    "            batch_x = Variable(torch.FloatTensor(batch_x))\n",
    "            batch_y = Variable(torch.LongTensor(batch_y))\n",
    "            batch_y = batch_y.reshape(batch_y.shape[0])\n",
    "            #print(batch_x.shape)\n",
    "            #print(batch_x[0])\n",
    "            encoder_hidden = Variable(net.H_t0(batch_y.shape[0]))\n",
    "            output = net(batch_x,encoder_hidden)\n",
    "            output = output.reshape(batch_y.shape[0],3)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.data[0]\n",
    "        epoch_loss /= int(len(x_tweet_train)/batch_size)+1\n",
    "        epoch_losses.append(epoch_loss)\n",
    "    \n",
    "    encoder_hidden_test = Variable(net.H_t0(len(x_tweet_test)))\n",
    "    predicted_output = net(x_tweet_test,encoder_hidden_test)\n",
    "    predicted_output = predicted_output.reshape(len(x_tweet_test),3)\n",
    "    predicted_output = predicted_output.detach().numpy()\n",
    "    predicted_output = np.argmax(predicted_output,axis = 1)\n",
    "    predicted_list[one] = predicted_output\n",
    "    ground_truth[one] = y_label_test\n",
    "    accuracy = accuracy_score(predicted_output,y_label_test)\n",
    "    print(accuracy)\n",
    "    plt.plot(epoch_losses)\n",
    "    plt.show()\n",
    "    epoch_loss_all_issues[one] = epoch_losses\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected torch.FloatTensor (got torch.LongTensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-625356ca7741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_tweet_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_label_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tweet_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_label_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredicted_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tweet_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_hidden_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredicted_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tweet_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredicted_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredicted_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected torch.FloatTensor (got torch.LongTensor)"
     ]
    }
   ],
   "source": [
    "x_tweet_test, y_label_test = Variable(torch.FloatTensor(x_tweet_test)), Variable(torch.LongTensor(y_label_test))\n",
    "predicted_output = net(x_tweet_test,encoder_hidden_test)\n",
    "predicted_output = predicted_output.reshape(len(x_tweet_test),3)\n",
    "predicted_output = predicted_output.detach().numpy()\n",
    "predicted_output = np.argmax(predicted_output,axis = 1)\n",
    "predicted_list[one] = predicted_output\n",
    "ground_truth[one] = y_label_test\n",
    "accuracy = accuracy_score(predicted_output,y_label_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'GST': array([1, 2, 0, ..., 2, 2, 2])}) defaultdict(<class 'list'>, {'GST': tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        ...,\n",
      "        [2],\n",
      "        [2],\n",
      "        [2]])})\n"
     ]
    }
   ],
   "source": [
    "print(predicted_list,ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = predicted_output.reshape(2577,3)\n",
    "pp = pp.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(pp,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(pred)):\n",
    "    if(pred[i]==y_label_test[i]):\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "leng =0\n",
    "sent = None\n",
    "for i in tweets_train:\n",
    "    if(len(i.split())>leng):\n",
    "        leng = len(i.split())\n",
    "        sent = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bedanta/ml/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.6815654 ,  0.23109291,  0.04126755,  0.8846598 , -0.4361313 ,\n",
       "        -0.21456827,  0.65924495,  0.33994016, -0.525895  ,  0.5834844 ,\n",
       "         0.6653589 ,  0.29341415, -0.36471903,  0.18188491,  0.32730228,\n",
       "         0.79123586,  0.02781718, -0.33711672, -0.80121267,  0.6252979 ,\n",
       "        -0.70709896, -0.57461244, -0.6148937 , -1.3081862 ,  0.04567234,\n",
       "        -1.2198802 ,  2.0235052 ,  0.52143574,  0.07138907, -0.30708632,\n",
       "        -0.48866588,  1.0021917 , -0.24938682, -1.1866249 ,  0.5651183 ,\n",
       "         0.99180627,  0.8333092 ,  0.1810268 ,  0.12759084, -0.04738565,\n",
       "        -0.8422463 ,  1.3016002 ,  0.12904184,  0.36956754,  0.10573836,\n",
       "        -1.2728429 , -0.04033704, -0.25919315,  0.2909471 ,  1.3154044 ,\n",
       "        -0.44838372, -0.00372123,  0.6192967 , -0.9946419 , -0.3310431 ,\n",
       "        -0.34398824,  0.37154832,  0.29375723,  0.32580638, -0.5869941 ,\n",
       "         1.0872732 ,  1.0318904 ,  0.26881853,  0.61623305, -0.69587684,\n",
       "        -0.17483798, -0.06561828, -0.49363068, -0.6286932 ,  0.0826534 ,\n",
       "        -0.7868127 , -0.16615576,  0.03265908,  0.9051269 , -0.31879243,\n",
       "        -0.29568535, -0.66492784,  0.53911436, -0.5349845 , -0.2590294 ,\n",
       "        -0.05879547, -0.50252306,  0.8863302 ,  0.24498208, -0.92815983,\n",
       "        -1.6827886 , -1.0952485 ,  0.6376884 ,  1.2977    ,  0.5373241 ,\n",
       "         0.20412068,  0.4332428 , -1.2194219 , -0.50240844,  1.2685869 ,\n",
       "         0.21505637,  0.29346755,  0.18202554, -1.0212481 , -0.34262624]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wv[['now']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
