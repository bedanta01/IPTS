{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import codecs\n",
    "from collections import Counter,defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_dataframe = pd.read_csv(\"../data/Labelled_tweets_v1.csv\",header = None)\n",
    "tweets = []\n",
    "data_pd = pd.read_csv(\"../data/Labelled_tweets_v1.csv\")\n",
    "#print(data_pd.head(10))\n",
    "data_tweet = data_pd['Tweet']\n",
    "for i in data_tweet:\n",
    "  j = i.split()\n",
    "  for k in j:\n",
    "    tweets.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_pd = data_pd['Issue']\n",
    "stance_pd = data_pd['Stance']\n",
    "\n",
    "all_words = tweets\n",
    "word2cnt = Counter(all_words)\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('vocab_real.csv', 'w', 'utf-8') as fout:\n",
    "  fout.write(\"{}{}1000000000\\n{}{}1000000000\\n{}{}1000000000\\n{}{}1000000000\\n\".format(\"<PAD>\",\",\", \"<UNK>\",\",\", \"<S>\",\",\", \"</S>\",\",\"))\n",
    "  for word, cnt in word2cnt.most_common(len(word2cnt)):\n",
    "    if(word not in stop_words):\n",
    "      fout.write(\"{}{}{} \\n\".format(word,',',cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GST', 'PNB Scam', 'FDIPolicy', 'Padmavati film screening', 'Cauvery SC Verdict', 'Jallikattu ban', 'GDP growth', 'RightToPrivacy SC Verdict', 'Demonetisation', 'Swacch Bharat', 'Aadhar linking', 'Triple Talaq SC verdict', 'TripleTalaqBill', 'lgp price hike', 'reservation', 'Beef Ban', 'Inflation control', 'nsc and ppf rate cuts', 'Ram Mandir', 'EVM tampering', 'Fodder scam', 'hike in oil prices', 'Rohingyas', 'acchedin']\n",
      "[['a no of people approach me daily worried abt the safety of their money in banks considering large no of bank frauds coming to light daily pm may kindly inform the public which bank is safe for people to keep their money URL sir there is a big rumour people are very skeptical that their saved money in the banks can go for a toss anytime hope wish pray that you our people all of us save the hard earned money in banks improve our incomes strengthen the income tax system'\n",
      "  'ArvindKejriwal' 'AAP' 'GST' 'Disagreement']\n",
      " ['its now revealed that our fms silence on the pnb scam was to protect his lawyer daughter who was paid a large retainer by the accused just a month before the scam became public when other law firms of the accused have been raided by the cbi why not hers modirobsindia URL you know doing something right when the ruling dispensation tries to rebut a story that has not even been published yet URL'\n",
      "  'ArvindKejriwal' 'AAP' 'PNB Scam' 'Neutral']\n",
      " ['pnb scam started in is going on till today the bjp is accusing the cong and cong bjp is also on the side of cong pnb scam started in is going on till today the bjp is accusing the cong and cong bjp is the only one that all the scams of cong time are still going on earlier cong was earning now the bjp earns from those scams that is why till today the bjp has not sent a single congressman to jail in any scam'\n",
      "  'ArvindKejriwal' 'AAP' 'PNB Scam' 'Neutral']\n",
      " ['would bjp confirm this if true what transpired in that meeting breaking my sources tell me that niravmodi his brother had a privileged private meeting with USER_MENTION in davos'\n",
      "  'ArvindKejriwal' 'AAP' 'PNB Scam' 'Neutral']\n",
      " ['bjp insiders telling that niravmodi been a regular donor to the party coffers since modi was cm that is primarily the reason behind his closer proximity to pmo why pm decided to look the other way it is just not a bank fraud but has all the ingrediants of a massive scam URL breaking cnnnews18 has accessed complainant letter to pmo on nirav modi complainant received acknowledgment from pmo over letter in USER_MENTION with details bigbankscam'\n",
      "  'ArvindKejriwal' 'AAP' 'PNB Scam' 'Neutral']]\n"
     ]
    }
   ],
   "source": [
    "issues = []\n",
    "for iss in issues_pd:\n",
    "  if iss not in issues:\n",
    "    issues.append(iss)\n",
    "    \n",
    "print(issues)\n",
    "\n",
    "word_counts = pd.read_csv(\"vocab_real.csv\",header=None)\n",
    "data_list = data_pd.values\n",
    "print(data_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'no', 'of', 'people', 'approach', 'me', 'daily', 'worried', 'abt', 'the', 'safety', 'of', 'their', 'money', 'in', 'banks', 'considering', 'large', 'no', 'of', 'bank', 'frauds', 'coming', 'to', 'light', 'daily', 'pm', 'may', 'kindly', 'inform', 'the', 'public', 'which', 'bank', 'is', 'safe', 'for', 'people', 'to', 'keep', 'their', 'money', 'URL', 'sir', 'there', 'is', 'a', 'big', 'rumour', 'people', 'are', 'very', 'skeptical', 'that', 'their', 'saved', 'money', 'in', 'the', 'banks', 'can', 'go', 'for', 'a', 'toss', 'anytime', 'hope', 'wish', 'pray', 'that', 'you', 'our', 'people', 'all', 'of', 'us', 'save', 'the', 'hard', 'earned', 'money', 'in', 'banks', 'improve', 'our', 'incomes', 'strengthen', 'the', 'income', 'tax', 'system'], ['its', 'now', 'revealed', 'that', 'our', 'fms', 'silence', 'on', 'the', 'pnb', 'scam', 'was', 'to', 'protect', 'his', 'lawyer', 'daughter', 'who', 'was', 'paid', 'a', 'large', 'retainer', 'by', 'the', 'accused', 'just', 'a', 'month', 'before', 'the', 'scam', 'became', 'public', 'when', 'other', 'law', 'firms', 'of', 'the', 'accused', 'have', 'been', 'raided', 'by', 'the', 'cbi', 'why', 'not', 'hers', 'modirobsindia', 'URL', 'you', 'know', 'doing', 'something', 'right', 'when', 'the', 'ruling', 'dispensation', 'tries', 'to', 'rebut', 'a', 'story', 'that', 'has', 'not', 'even', 'been', 'published', 'yet', 'URL'], ['pnb', 'scam', 'started', 'in', 'is', 'going', 'on', 'till', 'today', 'the', 'bjp', 'is', 'accusing', 'the', 'cong', 'and', 'cong', 'bjp', 'is', 'also', 'on', 'the', 'side', 'of', 'cong', 'pnb', 'scam', 'started', 'in', 'is', 'going', 'on', 'till', 'today', 'the', 'bjp', 'is', 'accusing', 'the', 'cong', 'and', 'cong', 'bjp', 'is', 'the', 'only', 'one', 'that', 'all', 'the', 'scams', 'of', 'cong', 'time', 'are', 'still', 'going', 'on', 'earlier', 'cong', 'was', 'earning', 'now', 'the', 'bjp', 'earns', 'from', 'those', 'scams', 'that', 'is', 'why', 'till', 'today', 'the', 'bjp', 'has', 'not', 'sent', 'a', 'single', 'congressman', 'to', 'jail', 'in', 'any', 'scam'], ['would', 'bjp', 'confirm', 'this', 'if', 'true', 'what', 'transpired', 'in', 'that', 'meeting', 'breaking', 'my', 'sources', 'tell', 'me', 'that', 'niravmodi', 'his', 'brother', 'had', 'a', 'privileged', 'private', 'meeting', 'with', 'USER_MENTION', 'in', 'davos'], ['bjp', 'insiders', 'telling', 'that', 'niravmodi', 'been', 'a', 'regular', 'donor', 'to', 'the', 'party', 'coffers', 'since', 'modi', 'was', 'cm', 'that', 'is', 'primarily', 'the', 'reason', 'behind', 'his', 'closer', 'proximity', 'to', 'pmo', 'why', 'pm', 'decided', 'to', 'look', 'the', 'other', 'way', 'it', 'is', 'just', 'not', 'a', 'bank', 'fraud', 'but', 'has', 'all', 'the', 'ingrediants', 'of', 'a', 'massive', 'scam', 'URL', 'breaking', 'cnnnews18', 'has', 'accessed', 'complainant', 'letter', 'to', 'pmo', 'on', 'nirav', 'modi', 'complainant', 'received', 'acknowledgment', 'from', 'pmo', 'over', 'letter', 'in', 'USER_MENTION', 'with', 'details', 'bigbankscam']]\n"
     ]
    }
   ],
   "source": [
    "data_tweet = data_tweet.values.tolist()\n",
    "for i in range(0,len(data_tweet)):\n",
    "    data_tweet[i] = data_tweet[i].split()\n",
    "    \n",
    "print(data_tweet[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tweet_size = 0\n",
    "for i in data_tweet:\n",
    "    if(len(i)>max_tweet_size):\n",
    "        max_tweet_size = len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tweet_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = stopwords.words('english') + list(string.punctuation) + ['will', 'also', 'said','a','URL','USER_MENTION']\n",
    "tweets_after_stop_words=[]\n",
    "for i in data_tweet:\n",
    "    tweet = []\n",
    "    for j in i:\n",
    "        if(j not in stopset):\n",
    "            tweet.append(j)\n",
    "    tweets_after_stop_words.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wv = Word2Vec(data_tweet,min_count=0,window=5,size=100)\n",
    "#len(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bedanta/ml/lib/python3.5/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "tweet_vectors =[]\n",
    "for i in range(0,len(tweets_after_stop_words)):\n",
    "    tweet_vectors.append(model_wv[tweets_after_stop_words[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_after_stop_words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,vocab_size, hidden_size,input_size):\n",
    "        super(Net,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.word_embeddings = nn.Embedding(vocab_size+106,100)\n",
    "        self.GRU = nn.GRU(100,self.hidden_size,num_layers = 1, batch_first = True)\n",
    "        self.linear = nn.Linear(self.hidden_size, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.linear_label = nn.Linear(self.input_size, hidden_size)\n",
    "        self.out_label = nn.Linear(self.hidden_size,self.output_size_label)\n",
    "    \n",
    "    def forward(self,x_input,hidden_state):\n",
    "        embedded = self.word_embeddings(x_input)\n",
    "        #print(embedded.shape)\n",
    "        #output = embedded.view(-1,-1, self.hidden_size)\n",
    "        output, hn = self.GRU(embedded)\n",
    "        #hn_ = hn[0].reshape(x_input.shape[0],output.shape[1]*output.shape[2])\n",
    "        #print(output.shape)\n",
    "        #linear = self.linear(hn)\n",
    "        #print(linear.shape)\n",
    "        output_1 = self.linear_issue(hn)\n",
    "        output_1 = F.relu(output_1)\n",
    "        output_1 = self.out_issue(output_1)\n",
    "        output_1 = self.softmax(output_1)\n",
    "        \n",
    "        return class_labels\n",
    "\n",
    "    def H_t0(self, batch_size):\n",
    "        return torch.zeros(1,batch_size,self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issue_vocab(issues,want = 'issue2id'):\n",
    "    if(want == 'issue2id'):\n",
    "        issue2idx = {issue:idx for idx,issue in enumerate(issues)}\n",
    "        return issue2idx\n",
    "    \n",
    "    else:\n",
    "        idx2issue = {idx:issue for idx,issue in enumerate(issues)}\n",
    "        return idx2issue\n",
    "    \n",
    "def sent_vocab(want = 'sent2id'):\n",
    "    sent2id = {'Disagreement':0,'Neutral':1,'Agreement':2}\n",
    "    id2sent = {0:'Disagreement',1:'Neutral',2:'Agreement'}\n",
    "    if(want == 'sent2id'):\n",
    "        return sent2id\n",
    "\n",
    "    else:\n",
    "        #idx2issue = {idx:issue for idx,issue in enumerate(issues)}\n",
    "        return idx2sent\n",
    "\n",
    "def load_vocab():\n",
    "    load_words = open(\"vocab_real.csv\").readlines()\n",
    "    for i in range(len(load_words)):\n",
    "        load_words[i] = load_words[i].split(',')\n",
    "    vocab = [load_words[i][0] for i in range(len(load_words))]\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    idx2word = {idx: word for idx, word in enumerate(vocab)}\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(tweets, issue_, sentiments,issues):\n",
    "    #print(len(tweets))\n",
    "    stop_words = ['the','of','in','and','a','is','on','this','all','it','will','for','to','be','with',\n",
    "              'at','are','u','has','that','by','from', 'as','was','have','its','an','if','been','be','also','should','which']\n",
    "    max_tweet_size = 120\n",
    "    word2idx,idx2word = load_vocab()\n",
    "    issue2idx = issue_vocab(issues,'issue2id')\n",
    "    sent2idx = sent_vocab()\n",
    "\n",
    "    x_tweet, y_issue, y_label = [], [], []\n",
    "    for tweet,issue,sent in zip(tweets, issue_, sentiments):\n",
    "        x = [word2idx.get(word, 1) for word in (tweet + u\" </S>\").split() if word not in stop_words]\n",
    "        x = np.array(x)\n",
    "        t = np.zeros(max_tweet_size)\n",
    "        if len(x)<=max_tweet_size:\n",
    "            t[:len(x)] = x\n",
    "        else:\n",
    "            t = x[:max_tweet_size]\n",
    "\n",
    "        #print(issue)\n",
    "        y_i = [issue2idx.get(issue,1)]\n",
    "        y_l = [sent2idx.get(sent,1)]\n",
    "\n",
    "        x_tweet.append(t)\n",
    "        y_issue.append(y_i)\n",
    "        y_label.append(y_l)\n",
    "    #print(len(x_tweet))\n",
    "    return np.array(x_tweet), np.array(y_issue), np.array(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches_train(data_x,data_y,batch_size, idx):\n",
    "    start =  batch_size*idx\n",
    "    end = start + batch_size\n",
    "    if(end>len(data_x)):\n",
    "        return data_x[start:], data_y[start:]\n",
    "    return data_x[start:end], data_y[start:end]\n",
    "\n",
    "def batches_test(data_x,data_y,batch_size, idx):\n",
    "    start =  batch_size*idx\n",
    "    end = start + batch_size\n",
    "    return data_x[start:end], data_y[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_issues = 24#len(issues)\n",
    "epochs = 10\n",
    "input_size = 100\n",
    "vocab_size = len(word_counts)\n",
    "output_size_issue = num_issues\n",
    "output_size_label = 3\n",
    "hidden_size = 256\n",
    "batch_size = 32\n",
    "#n_iters = int(len(x_train)/batch_size)\n",
    "lr = 0.01\n",
    "\n",
    "num_issues = len(issues_pd.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss_all_issues = defaultdict(list)\n",
    "metrics_dict = defaultdict(list)\n",
    "predicted_list = defaultdict(list)\n",
    "ground_truth = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_wv(tweets, issue_, sentiments,issues):\n",
    "    stop_words = ['the','of','in','and','a','is','on','this','all','it','will','for','to','be','with',\n",
    "              'at','are','u','has','that','by','from', 'as','was','have','its','an','if','been','be','also','should','which']\n",
    "    #print(tweets[0])\n",
    "#     leng = 0\n",
    "#     for i in tweets:\n",
    "#         len_ = len(i.split())\n",
    "#         if(len_ > leng):\n",
    "#             leng = len_\n",
    "    \n",
    "    max_tweet_size = 120\n",
    "    word2idx,idx2word = load_vocab()\n",
    "    issue2idx = issue_vocab(issues,'issue2id')\n",
    "    sent2idx = sent_vocab()\n",
    "    tweets_train=[]\n",
    "        \n",
    "\n",
    "    x_tweet, y_issue, y_label = [], [], []\n",
    "    for tweet,issue,sent in zip(tweets, issue_, sentiments):\n",
    "        x = [model_wv[word] for word in tweet.split() if word not in stopset+stop_words]\n",
    "        t = np.zeros([max_tweet_size,100])\n",
    "        if len(x)<=max_tweet_size:\n",
    "            t[:len(x)] = x\n",
    "        else:\n",
    "            t = x[:max_tweet_size]\n",
    "\n",
    "        y_i = [issue2idx.get(issue,1)]\n",
    "        y_l = [sent2idx.get(sent,1)]\n",
    "\n",
    "        x_tweet.append(t)\n",
    "        y_issue.append(y_i)\n",
    "        y_label.append(y_l)\n",
    "        \n",
    "    return np.array(x_tweet), np.array(y_issue), np.array(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bedanta/ml/lib/python3.5/site-packages/ipykernel_launcher.py:45: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3550640279394645\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for one in issues:\n",
    "    net = Net(vocab_size, hidden_size,100)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(),lr=0.1)\n",
    "    \n",
    "    \n",
    "    if(one == '0'):\n",
    "        continue\n",
    "    data_withot_one_issue = data_pd[data_pd.Issue != one]\n",
    "    data_with_the_issue = data_pd[data_pd.Issue == one]\n",
    "    \n",
    "    data_list_with = data_withot_one_issue.values\n",
    "    data_list_without = data_with_the_issue.values\n",
    "    \n",
    "    tweets_train = data_list_with[:,0]\n",
    "    #print(tweets_train[0])\n",
    "    issue_train = data_list_with[:,3]\n",
    "    label_train = data_list_with[:,4]\n",
    "    tweets_test = data_list_without[:,0]\n",
    "    issue_test = data_list_without[:,3]\n",
    "    label_test = data_list_without[:,4]\n",
    "    \n",
    "    x_tweet_train,y_issue_train, y_label_train = create_data(tweets_train,issue_train,label_train,issues)\n",
    "    #print(x_tweet_train[0])\n",
    "    x_tweet_test,y_issue_test, y_label_test = create_data(tweets_test,issue_test,label_test,issues)\n",
    "    x_tweet_test, y_label_test = Variable(torch.LongTensor(x_tweet_test)), Variable(torch.LongTensor(y_label_test))\n",
    "    #print(x_tweet_test)\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    epoch_losses = []\n",
    "    for e in range(0,2):\n",
    "        epoch_loss = 0\n",
    "        for idx in range(0,int(len(x_tweet_train)/batch_size)+1):\n",
    "            net.zero_grad()\n",
    "            batch_x, batch_y = batches_train(x_tweet_train,y_label_train,batch_size,idx)\n",
    "            batch_x = Variable(torch.LongTensor(batch_x))\n",
    "            batch_y = Variable(torch.LongTensor(batch_y))\n",
    "            batch_y = batch_y.reshape(batch_y.shape[0])\n",
    "            encoder_hidden = Variable(net.H_t0(batch_y.shape[0]))\n",
    "            output = net(batch_x,encoder_hidden)\n",
    "            loss = criterion(output[0], batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.data[0]\n",
    "        epoch_loss /= len(x_tweet_train)/batch_size\n",
    "        epoch_losses.append(epoch_loss)\n",
    "    \n",
    "    encoder_hidden_test = Variable(net.H_t0(len(x_tweet_test)))\n",
    "    predicted_output = net(x_tweet_test,encoder_hidden_test)\n",
    "    predicted_output = predicted_output.reshape(len(x_tweet_test),3)\n",
    "    predicted_output = predicted_output.detach().numpy()\n",
    "    predicted_output = np.argmax(predicted_output,axis = 1)\n",
    "    predicted_list[one] = predicted_output\n",
    "    ground_truth[one] = y_label_test\n",
    "    accuracy = accuracy_score(predicted_output,y_label_test)\n",
    "    print(accuracy)\n",
    "    plt.plot(epoch_losses)\n",
    "    plt.show()\n",
    "    epoch_loss_all_issues[one] = epoch_losses\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11757857974388825\n"
     ]
    }
   ],
   "source": [
    "#x_tweet_test, y_label_test = Variable(torch.FloatTensor(x_tweet_test)), Variable(torch.LongTensor(y_label_test))\n",
    "predicted_output = net(x_tweet_test,encoder_hidden_test)\n",
    "predicted_output = predicted_output.reshape(len(x_tweet_test),3)\n",
    "predicted_output = predicted_output.detach().numpy()\n",
    "predicted_output = np.argmax(predicted_output,axis = 1)\n",
    "predicted_list[one] = predicted_output\n",
    "ground_truth[one] = y_label_test\n",
    "accuracy = accuracy_score(predicted_output,y_label_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8df41a2588>]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = predicted_output.reshape(2577,3)\n",
    "pp = pp.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bedanta/ml/lib/python3.5/site-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "x_tweet_test,y_issue_test, y_label_test = create_data_wv(tweets_test,issue_test,label_test,issues)\n",
    "x_tweet_test = Variable(torch.FloatTensor(x_tweet_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(pred)):\n",
    "    if(pred[i]==y_label_test[i]):\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "leng =0\n",
    "sent = None\n",
    "for i in tweets_train:\n",
    "    if(len(i.split())>leng):\n",
    "        leng = len(i.split())\n",
    "        sent = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(output,dim = 2)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.load('predicted_list.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(defaultdict(<class 'list'>, {'RightToPrivacy SC Verdict': array([1, 1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1]), 'reservation': array([0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 2, 2, 0,\n",
       "       2, 0, 0, 0, 2, 1, 1, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0,\n",
       "       0, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0,\n",
       "       0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 2, 1, 2,\n",
       "       0, 2, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0,\n",
       "       0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0,\n",
       "       0, 0, 0, 2]), 'Swacch Bharat': array([0, 2, 2, 2, 1, 2, 2, 1, 2, 0, 2, 2, 1, 1, 0, 0, 2, 2, 2, 0, 0, 0,\n",
       "       0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 0, 2, 0, 2, 2, 2, 2, 1, 2, 0,\n",
       "       0, 0, 0, 2, 2, 0, 2, 1, 0, 0, 0, 0, 2, 0, 2, 2, 0, 1, 0, 2, 0, 2,\n",
       "       0, 0, 0, 0, 2, 2, 1, 1, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0,\n",
       "       0, 2, 2, 0, 2, 2, 0, 1, 0, 0, 2, 1, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0,\n",
       "       2, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0,\n",
       "       0, 0, 1, 2, 2, 2, 2, 1, 2, 2, 2, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 1, 0, 2,\n",
       "       2, 2, 1, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0,\n",
       "       0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0,\n",
       "       0, 0, 0]), 'Triple Talaq SC verdict': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 0, 1, 0, 1, 0, 1, 2, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1]), 'Demonetisation': array([2, 2, 0, ..., 2, 2, 2]), 'lgp price hike': array([0, 0, 2, 2, 0, 2, 1, 0, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 2, 2, 1, 0, 0, 2, 2, 2,\n",
       "       2, 0, 0, 2, 0, 0, 0, 2, 2, 1, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0,\n",
       "       2, 1, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 1, 0, 0,\n",
       "       0, 2, 0, 2, 2, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 2, 1, 0, 2, 2, 1,\n",
       "       0, 0, 0, 2, 2, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2,\n",
       "       0, 0, 2, 0, 2, 1, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2,\n",
       "       0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0,\n",
       "       1, 0, 2, 1, 2, 2, 0, 2, 2, 0, 0, 2, 1, 2, 1, 2, 0, 1, 0, 1, 0, 0,\n",
       "       2, 2, 0, 0, 1, 0, 0]), 'PNB Scam': array([2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 2, 2, 0,\n",
       "       2, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 2, 0, 0,\n",
       "       2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 1, 0, 2, 2, 0,\n",
       "       0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2,\n",
       "       1, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,\n",
       "       2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0,\n",
       "       0, 2, 2, 0, 2, 0, 0, 2, 0]), 'Aadhar linking': array([2, 2, 0, 0, 2, 2, 0, 1, 0, 2, 1, 0, 0, 0, 1, 0, 1, 0, 2, 1, 1, 0,\n",
       "       2, 2, 1, 1, 2, 2, 0, 0, 0, 1, 1, 2, 1, 0, 1, 0, 0, 1, 2, 2, 0, 0,\n",
       "       0, 0, 1, 1, 2, 0, 0, 1, 0, 0, 0, 2, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 2, 2, 1, 0, 1, 1, 2, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 2, 1, 1, 0, 0, 0, 1, 1, 0, 2, 0, 2, 0, 0, 0, 0, 0,\n",
       "       2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 0, 0, 2, 1, 1, 2, 0, 0, 0, 1, 1, 2,\n",
       "       0, 1, 2, 2, 0, 0, 0, 0, 2]), 'GDP growth': array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2]), 'Beef Ban': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "       0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2,\n",
       "       2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]), 'GST': array([0, 0, 0, ..., 2, 0, 0]), 'TripleTalaqBill': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "       2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1,\n",
       "       0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "       0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]), 'acchedin': array([2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 1, 0, 0, 2, 0, 0, 0, 1, 0, 2,\n",
       "       0, 0, 2, 1, 1, 2, 2, 0, 1, 1, 2, 2, 0, 2, 2, 0, 2, 0, 1, 1, 1, 1,\n",
       "       0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 1, 1, 2, 2, 2,\n",
       "       1, 1, 1, 2, 0, 2, 0, 1, 1, 0, 2, 0, 0, 0, 0, 2, 2, 0]), 'Inflation control': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0,\n",
       "       0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 2, 0,\n",
       "       0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "       0, 2, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 1, 1, 0, 1, 0, 2, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]), 'Ram Mandir': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0]), 'Cauvery SC Verdict': array([1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 2,\n",
       "       1, 0, 0, 2, 0, 0, 0, 1, 1, 1, 1, 2, 2, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0]), 'Jallikattu ban': array([0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0,\n",
       "       0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'nsc and ppf rate cuts': array([0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]), 'Fodder scam': array([2, 2, 2, 1, 1, 2, 2, 0, 0, 0, 0, 2, 0, 2, 2, 2, 0, 1, 0, 2, 0, 2,\n",
       "       2, 2, 1, 1, 2, 2, 0, 1, 0, 2, 2, 2, 2, 0, 0, 2, 2, 1, 0, 2, 0, 2,\n",
       "       0, 2, 0, 0, 2, 2, 2, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0,\n",
       "       2, 2]), 'hike in oil prices': array([2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0,\n",
       "       0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2,\n",
       "       0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0,\n",
       "       0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0,\n",
       "       0, 0, 0, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0,\n",
       "       2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0,\n",
       "       2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "       0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2,\n",
       "       2, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2,\n",
       "       2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0]), 'Padmavati film screening': array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0]), 'Rohingyas': array([1, 2, 0, 2, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1]), 'FDIPolicy': array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2,\n",
       "       0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0,\n",
       "       2, 0, 1, 2, 2, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 2, 1, 0, 0,\n",
       "       0]), 'EVM tampering': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 2, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0,\n",
       "       2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 2, 2, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 2,\n",
       "       1, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "       2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0])}), dtype=object)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
