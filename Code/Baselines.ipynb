{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>UserHandle</th>\n",
       "      <th>Party</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a no of people approach me daily worried abt t...</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>AAP</td>\n",
       "      <td>GST</td>\n",
       "      <td>Disagreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>its now revealed that our fms silence on the p...</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>AAP</td>\n",
       "      <td>PNB Scam</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pnb scam started in is going on till today the...</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>AAP</td>\n",
       "      <td>PNB Scam</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>would bjp confirm this if true what transpired...</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>AAP</td>\n",
       "      <td>PNB Scam</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bjp insiders telling that niravmodi been a reg...</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>AAP</td>\n",
       "      <td>PNB Scam</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet      UserHandle Party  \\\n",
       "0  a no of people approach me daily worried abt t...  ArvindKejriwal   AAP   \n",
       "1  its now revealed that our fms silence on the p...  ArvindKejriwal   AAP   \n",
       "2  pnb scam started in is going on till today the...  ArvindKejriwal   AAP   \n",
       "3  would bjp confirm this if true what transpired...  ArvindKejriwal   AAP   \n",
       "4  bjp insiders telling that niravmodi been a reg...  ArvindKejriwal   AAP   \n",
       "\n",
       "      Issue        Stance  \n",
       "0       GST  Disagreement  \n",
       "1  PNB Scam       Neutral  \n",
       "2  PNB Scam       Neutral  \n",
       "3  PNB Scam       Neutral  \n",
       "4  PNB Scam       Neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataframe = pd.read_csv(\"../data/Labelled_tweets_v1.csv\")\n",
    "raw_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Agreement' 'Disagreement' 'Neutral']\n",
      "{'Agreement': 0, 'Disagreement': 1, 'Neutral': 2}\n",
      "['Aadhar linking' 'Beef Ban' 'Cauvery SC Verdict' 'Demonetisation'\n",
      " 'EVM tampering' 'FDIPolicy' 'Fodder scam' 'GDP growth' 'GST'\n",
      " 'Inflation control' 'Jallikattu ban' 'PNB Scam'\n",
      " 'Padmavati film screening' 'Ram Mandir' 'RightToPrivacy SC Verdict'\n",
      " 'Rohingyas' 'Swacch Bharat' 'Triple Talaq SC verdict' 'TripleTalaqBill'\n",
      " 'acchedin' 'hike in oil prices' 'lgp price hike' 'nsc and ppf rate cuts'\n",
      " 'reservation']\n",
      "{'nsc and ppf rate cuts': 22, 'Triple Talaq SC verdict': 17, 'GDP growth': 7, 'Cauvery SC Verdict': 2, 'EVM tampering': 4, 'Demonetisation': 3, 'hike in oil prices': 20, 'FDIPolicy': 5, 'lgp price hike': 21, 'Swacch Bharat': 16, 'PNB Scam': 11, 'RightToPrivacy SC Verdict': 14, 'reservation': 23, 'Aadhar linking': 0, 'Padmavati film screening': 12, 'Ram Mandir': 13, 'Inflation control': 9, 'Beef Ban': 1, 'GST': 8, 'TripleTalaqBill': 18, 'Fodder scam': 6, 'Jallikattu ban': 10, 'Rohingyas': 15, 'acchedin': 19}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>UserHandle</th>\n",
       "      <th>Party</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a no of people approach me daily worried abt t...</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>AAP</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>its now revealed that our fms silence on the p...</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>AAP</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pnb scam started in is going on till today the...</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>AAP</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>would bjp confirm this if true what transpired...</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>AAP</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bjp insiders telling that niravmodi been a reg...</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>AAP</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is it possible to believe that he or vijay mal...</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>AAP</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>someone told me today sealing bjp wants to rui...</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>AAP</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>if all state govts central govt and sc togethe...</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>AAP</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>three killings on merchants in one year first ...</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>AAP</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>there is no need to increase house tax in mcd ...</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>AAP</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet      UserHandle Party  \\\n",
       "0  a no of people approach me daily worried abt t...  ArvindKejriwal   AAP   \n",
       "1  its now revealed that our fms silence on the p...  ArvindKejriwal   AAP   \n",
       "2  pnb scam started in is going on till today the...  ArvindKejriwal   AAP   \n",
       "3  would bjp confirm this if true what transpired...  ArvindKejriwal   AAP   \n",
       "4  bjp insiders telling that niravmodi been a reg...  ArvindKejriwal   AAP   \n",
       "5  is it possible to believe that he or vijay mal...  ArvindKejriwal   AAP   \n",
       "6  someone told me today sealing bjp wants to rui...  ArvindKejriwal   AAP   \n",
       "7  if all state govts central govt and sc togethe...  ArvindKejriwal   AAP   \n",
       "8  three killings on merchants in one year first ...  ArvindKejriwal   AAP   \n",
       "9  there is no need to increase house tax in mcd ...  ArvindKejriwal   AAP   \n",
       "\n",
       "   Issue  Stance  \n",
       "0      8       1  \n",
       "1     11       2  \n",
       "2     11       2  \n",
       "3     11       2  \n",
       "4     11       2  \n",
       "5     11       2  \n",
       "6      5       2  \n",
       "7      5       2  \n",
       "8      8       1  \n",
       "9      8       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index on classes\n",
    "stance_df = raw_dataframe.Stance\n",
    "stances = np.unique(stance_df)\n",
    "print(stances)\n",
    "stance_idx = {}\n",
    "for i in range(len(stances)):\n",
    "    stance_idx[stances[i]] = i\n",
    "print(stance_idx)\n",
    "raw_dataframe.Stance.replace(to_replace = stance_idx, inplace = True)\n",
    "\n",
    "issue_df = raw_dataframe['Issue']\n",
    "issues = np.unique(issue_df)\n",
    "print(issues)\n",
    "issue_idx = {}\n",
    "for i in range(len(issues)):\n",
    "    issue_idx[issues[i]] = i\n",
    "print(issue_idx)\n",
    "raw_dataframe.Issue.replace(to_replace=issue_idx, inplace=True)\n",
    "raw_dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove selected stopwords from the dataset\n",
    "stop_words = ['the','of','in','and','a','is','on','this','all','it','will','for','to','be','with',\n",
    "              'at','are','u','has','that','by','from', 'as','was','have','its','an','if','been','be','also','should','which']\n",
    "for count, row in raw_dataframe.iterrows():\n",
    "    tweet = row['Tweet']\n",
    "    new_tweet = []\n",
    "    for word in tweet.split():\n",
    "        if word not in stop_words:\n",
    "            new_tweet.append(word)\n",
    "    raw_dataframe.iloc[count, 0] = ' '.join(new_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5753,) (5753,) (5753,)\n",
      "(719,) (719,) (719,)\n",
      "(720,) (720,) (720,)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train, test, validation\n",
    "raw_dataframe = raw_dataframe.sample(frac=1).reset_index(drop=True)\n",
    "X = raw_dataframe['Tweet'].values\n",
    "Y1 = raw_dataframe['Issue'].values\n",
    "Y2 = raw_dataframe['Stance'].values\n",
    "\n",
    "num = Y1.shape[0]\n",
    "pc_80 = int(0.8 * num)\n",
    "pc_90 = int(0.9 * num)\n",
    "\n",
    "# training dataset\n",
    "X_train = X[:pc_80]\n",
    "Y1_train = Y1[:pc_80]\n",
    "Y2_train = Y2[:pc_80]\n",
    "print(X_train.shape, Y1_train.shape, Y2_train.shape)\n",
    "\n",
    "\n",
    "# validation dataset\n",
    "X_val = X[pc_80:pc_90]\n",
    "Y1_val = Y1[pc_80:pc_90]\n",
    "Y2_val = Y2[pc_80:pc_90]\n",
    "print(X_val.shape, Y1_val.shape, Y2_val.shape)\n",
    "\n",
    "# Test dataset\n",
    "X_test = X[pc_90:]\n",
    "Y1_test = Y1[pc_90:]\n",
    "Y2_test = Y2[pc_90:]\n",
    "print(X_test.shape, Y1_test.shape, Y2_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5753, 15103)\n",
      "(719, 15103)\n",
      "(720, 15103)\n"
     ]
    }
   ],
   "source": [
    "# Get tfidf vectors for train, val and test\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "X_train_tf = tfidf_vec.fit_transform(X_train).toarray()\n",
    "print(X_train_tf.shape)\n",
    "\n",
    "X_val_tf = tfidf_vec.transform(X_val).toarray()\n",
    "print(X_val_tf.shape)\n",
    "\n",
    "X_test_tf = tfidf_vec.transform(X_test).toarray()\n",
    "print(X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue classification\n",
      "Accuracy:  0.5583333333333333\n",
      "Weighted F1 score:  0.5296565213662253\n",
      "Stance classification\n",
      "Accuracy:  0.625\n",
      "Weighted F1 score:  0.6279284417660259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bedanta/ml/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Apply Gaussian Naive Bayes directly for test dataset\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb1 = GaussianNB()\n",
    "y1_pred = gnb1.fit(X_train_tf, Y1_train).predict(X_test_tf)\n",
    "\n",
    "gnb2 = GaussianNB()\n",
    "y2_pred = gnb2.fit(X_train_tf, Y2_train).predict(X_test_tf)\n",
    "\n",
    "print('Issue classification')\n",
    "print('Accuracy: ', accuracy_score(Y1_test, y1_pred))\n",
    "print('Weighted F1 score: ', f1_score(Y1_test, y1_pred, average='weighted'))\n",
    "\n",
    "print('Stance classification')\n",
    "print('Accuracy: ', accuracy_score(Y2_test, y2_pred))\n",
    "print('Weighted F1 score: ', f1_score(Y2_test, y2_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue classification\n",
      "Accuracy:  0.44305555555555554\n",
      "Weighted F1 score:  0.332278575770555\n",
      "Stance classification\n",
      "Accuracy:  0.6930555555555555\n",
      "Weighted F1 score:  0.6410084003257671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bedanta/ml/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Apply Multinomial Naive Bayes directly for test dataset\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb1 = MultinomialNB()\n",
    "y1_pred = mnb1.fit(X_train_tf, Y1_train).predict(X_test_tf)\n",
    "\n",
    "mnb2 = MultinomialNB()\n",
    "y2_pred = mnb2.fit(X_train_tf, Y2_train).predict(X_test_tf)\n",
    "\n",
    "print('Issue classification')\n",
    "print('Accuracy: ', accuracy_score(Y1_test, y1_pred))\n",
    "print('Weighted F1 score: ', f1_score(Y1_test, y1_pred, average='weighted'))\n",
    "\n",
    "print('Stance classification')\n",
    "print('Accuracy: ', accuracy_score(Y2_test, y2_pred))\n",
    "print('Weighted F1 score: ', f1_score(Y2_test, y2_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([8]),)\n",
      "(array([0]),)\n",
      "Issue classification\n",
      "Accuracy:  0.3472222222222222\n",
      "Weighted F1 score:  0.17898052691867122\n",
      "Stance classification\n",
      "Accuracy:  0.46111111111111114\n",
      "Weighted F1 score:  0.2910435149978876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bedanta/ml/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Classify using majority vote in training dataset\n",
    "issue_counts = np.unique(Y1_train, return_counts=True)\n",
    "max_issue = max(issue_counts[1])\n",
    "print(np.where(issue_counts[1]==max_issue))\n",
    "\n",
    "stance_counts = np.unique(Y2_train, return_counts=True)\n",
    "max_stance =  max(stance_counts[1])\n",
    "print(np.where(stance_counts[1]==max_stance))\n",
    "\n",
    "y1_pred = np.array([8]*len(Y1_test))\n",
    "y2_pred = np.array([0]*len(Y2_test))\n",
    "\n",
    "print('Issue classification')\n",
    "print('Accuracy: ', accuracy_score(Y1_test, y1_pred))\n",
    "print('Weighted F1 score: ', f1_score(Y1_test, y1_pred, average='weighted'))\n",
    "\n",
    "print('Stance classification')\n",
    "print('Accuracy: ', accuracy_score(Y2_test, y2_pred))\n",
    "print('Weighted F1 score: ', f1_score(Y2_test, y2_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue classification\n",
      "Accuracy:  0.9541666666666667\n",
      "Weighted F1 score:  0.9530755966329344\n",
      "Stance classification\n",
      "Accuracy:  0.7416666666666667\n",
      "Weighted F1 score:  0.7324225317398608\n"
     ]
    }
   ],
   "source": [
    "# Classifiy using SVM classifier\n",
    "from sklearn.svm import SVC\n",
    "clf1 = SVC(gamma='auto', kernel='linear')\n",
    "clf1.fit(X_train_tf, Y1_train)\n",
    "y1_pred = clf1.predict(X_test_tf)\n",
    "\n",
    "clf2 = SVC(gamma='auto', kernel='linear')\n",
    "clf2.fit(X_train_tf, Y2_train)\n",
    "y2_pred = clf2.predict(X_test_tf)\n",
    "print('Issue classification')\n",
    "print('Accuracy: ', accuracy_score(Y1_test, y1_pred))\n",
    "print('Weighted F1 score: ', f1_score(Y1_test, y1_pred, average='weighted'))\n",
    "\n",
    "print('Stance classification')\n",
    "print('Accuracy: ', accuracy_score(Y2_test, y2_pred))\n",
    "print('Weighted F1 score: ', f1_score(Y2_test, y2_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue classification\n",
      "Accuracy:  0.8875\n",
      "Weighted F1 score:  0.8797122502523665\n",
      "Stance classification\n",
      "Accuracy:  0.7263888888888889\n",
      "Weighted F1 score:  0.7023813743644104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bedanta/ml/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Classify using Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log1 = LogisticRegression()\n",
    "y1_pred = log1.fit(X_train_tf, Y1_train).predict(X_test_tf)\n",
    "\n",
    "log2 = LogisticRegression()\n",
    "y2_pred = log2.fit(X_train_tf, Y2_train).predict(X_test_tf)\n",
    "\n",
    "print('Issue classification')\n",
    "print('Accuracy: ', accuracy_score(Y1_test, y1_pred))\n",
    "print('Weighted F1 score: ', f1_score(Y1_test, y1_pred, average='weighted'))\n",
    "\n",
    "print('Stance classification')\n",
    "print('Accuracy: ', accuracy_score(Y2_test, y2_pred))\n",
    "print('Weighted F1 score: ', f1_score(Y2_test, y2_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
