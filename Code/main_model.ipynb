{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import codecs\n",
    "from collections import Counter,defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Tweet      UserHandle Party  \\\n",
      "0  a no of people approach me daily worried abt t...  ArvindKejriwal   AAP   \n",
      "1  its now revealed that our fms silence on the p...  ArvindKejriwal   AAP   \n",
      "2  pnb scam started in is going on till today the...  ArvindKejriwal   AAP   \n",
      "\n",
      "      Issue        Stance  \n",
      "0       GST  Disagreement  \n",
      "1  PNB Scam       Neutral  \n",
      "2  PNB Scam       Neutral  \n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "tweets=[]\n",
    "data_pd = pd.read_csv(\"../data/Labelled_tweets_v1.csv\")\n",
    "print(data_pd.head(3))\n",
    "data_tweet = data_pd['Tweet']\n",
    "for i in data_tweet:\n",
    "    j = i.split()\n",
    "    tweets.append(j)\n",
    "    for k in j:\n",
    "        all_words.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_pd = data_pd['Issue']\n",
    "stance_pd = data_pd['Stance']\n",
    "\n",
    "#all_words = tweets\n",
    "word2cnt = Counter(all_words)\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('vocab_real.csv', 'w', 'utf-8') as fout:\n",
    "  fout.write(\"{}{}1000000000\\n{}{}1000000000\\n{}{}1000000000\\n{}{}1000000000\\n\".format(\"<PAD>\",\",\", \"<UNK>\",\",\", \"<S>\",\",\", \"</S>\",\",\"))\n",
    "  for word, cnt in word2cnt.most_common(len(word2cnt)):\n",
    "    if(word not in stop_words):\n",
    "      fout.write(\"{}{}{} \\n\".format(word,',',cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GST', 'PNB Scam', 'FDIPolicy', 'Padmavati film screening', 'Cauvery SC Verdict', 'Jallikattu ban', 'GDP growth', 'RightToPrivacy SC Verdict', 'Demonetisation', 'Swacch Bharat', 'Aadhar linking', 'Triple Talaq SC verdict', 'TripleTalaqBill', 'lgp price hike', 'reservation', 'Beef Ban', 'Inflation control', 'nsc and ppf rate cuts', 'Ram Mandir', 'EVM tampering', 'Fodder scam', 'hike in oil prices', 'Rohingyas', 'acchedin']\n",
      "[['a no of people approach me daily worried abt the safety of their money in banks considering large no of bank frauds coming to light daily pm may kindly inform the public which bank is safe for people to keep their money URL sir there is a big rumour people are very skeptical that their saved money in the banks can go for a toss anytime hope wish pray that you our people all of us save the hard earned money in banks improve our incomes strengthen the income tax system'\n",
      "  'ArvindKejriwal' 'AAP' 'GST' 'Disagreement']\n",
      " ['its now revealed that our fms silence on the pnb scam was to protect his lawyer daughter who was paid a large retainer by the accused just a month before the scam became public when other law firms of the accused have been raided by the cbi why not hers modirobsindia URL you know doing something right when the ruling dispensation tries to rebut a story that has not even been published yet URL'\n",
      "  'ArvindKejriwal' 'AAP' 'PNB Scam' 'Neutral']\n",
      " ['pnb scam started in is going on till today the bjp is accusing the cong and cong bjp is also on the side of cong pnb scam started in is going on till today the bjp is accusing the cong and cong bjp is the only one that all the scams of cong time are still going on earlier cong was earning now the bjp earns from those scams that is why till today the bjp has not sent a single congressman to jail in any scam'\n",
      "  'ArvindKejriwal' 'AAP' 'PNB Scam' 'Neutral']\n",
      " ['would bjp confirm this if true what transpired in that meeting breaking my sources tell me that niravmodi his brother had a privileged private meeting with USER_MENTION in davos'\n",
      "  'ArvindKejriwal' 'AAP' 'PNB Scam' 'Neutral']\n",
      " ['bjp insiders telling that niravmodi been a regular donor to the party coffers since modi was cm that is primarily the reason behind his closer proximity to pmo why pm decided to look the other way it is just not a bank fraud but has all the ingrediants of a massive scam URL breaking cnnnews18 has accessed complainant letter to pmo on nirav modi complainant received acknowledgment from pmo over letter in USER_MENTION with details bigbankscam'\n",
      "  'ArvindKejriwal' 'AAP' 'PNB Scam' 'Neutral']]\n"
     ]
    }
   ],
   "source": [
    "issues = []\n",
    "for iss in issues_pd:\n",
    "  if iss not in issues:\n",
    "    issues.append(iss)\n",
    "    \n",
    "print(issues)\n",
    "\n",
    "word_counts = pd.read_csv(\"vocab_real.csv\",header=None)\n",
    "data_list = data_pd.values\n",
    "print(data_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'no', 'of', 'people', 'approach', 'me', 'daily', 'worried', 'abt', 'the', 'safety', 'of', 'their', 'money', 'in', 'banks', 'considering', 'large', 'no', 'of', 'bank', 'frauds', 'coming', 'to', 'light', 'daily', 'pm', 'may', 'kindly', 'inform', 'the', 'public', 'which', 'bank', 'is', 'safe', 'for', 'people', 'to', 'keep', 'their', 'money', 'URL', 'sir', 'there', 'is', 'a', 'big', 'rumour', 'people', 'are', 'very', 'skeptical', 'that', 'their', 'saved', 'money', 'in', 'the', 'banks', 'can', 'go', 'for', 'a', 'toss', 'anytime', 'hope', 'wish', 'pray', 'that', 'you', 'our', 'people', 'all', 'of', 'us', 'save', 'the', 'hard', 'earned', 'money', 'in', 'banks', 'improve', 'our', 'incomes', 'strengthen', 'the', 'income', 'tax', 'system'], ['its', 'now', 'revealed', 'that', 'our', 'fms', 'silence', 'on', 'the', 'pnb', 'scam', 'was', 'to', 'protect', 'his', 'lawyer', 'daughter', 'who', 'was', 'paid', 'a', 'large', 'retainer', 'by', 'the', 'accused', 'just', 'a', 'month', 'before', 'the', 'scam', 'became', 'public', 'when', 'other', 'law', 'firms', 'of', 'the', 'accused', 'have', 'been', 'raided', 'by', 'the', 'cbi', 'why', 'not', 'hers', 'modirobsindia', 'URL', 'you', 'know', 'doing', 'something', 'right', 'when', 'the', 'ruling', 'dispensation', 'tries', 'to', 'rebut', 'a', 'story', 'that', 'has', 'not', 'even', 'been', 'published', 'yet', 'URL'], ['pnb', 'scam', 'started', 'in', 'is', 'going', 'on', 'till', 'today', 'the', 'bjp', 'is', 'accusing', 'the', 'cong', 'and', 'cong', 'bjp', 'is', 'also', 'on', 'the', 'side', 'of', 'cong', 'pnb', 'scam', 'started', 'in', 'is', 'going', 'on', 'till', 'today', 'the', 'bjp', 'is', 'accusing', 'the', 'cong', 'and', 'cong', 'bjp', 'is', 'the', 'only', 'one', 'that', 'all', 'the', 'scams', 'of', 'cong', 'time', 'are', 'still', 'going', 'on', 'earlier', 'cong', 'was', 'earning', 'now', 'the', 'bjp', 'earns', 'from', 'those', 'scams', 'that', 'is', 'why', 'till', 'today', 'the', 'bjp', 'has', 'not', 'sent', 'a', 'single', 'congressman', 'to', 'jail', 'in', 'any', 'scam'], ['would', 'bjp', 'confirm', 'this', 'if', 'true', 'what', 'transpired', 'in', 'that', 'meeting', 'breaking', 'my', 'sources', 'tell', 'me', 'that', 'niravmodi', 'his', 'brother', 'had', 'a', 'privileged', 'private', 'meeting', 'with', 'USER_MENTION', 'in', 'davos'], ['bjp', 'insiders', 'telling', 'that', 'niravmodi', 'been', 'a', 'regular', 'donor', 'to', 'the', 'party', 'coffers', 'since', 'modi', 'was', 'cm', 'that', 'is', 'primarily', 'the', 'reason', 'behind', 'his', 'closer', 'proximity', 'to', 'pmo', 'why', 'pm', 'decided', 'to', 'look', 'the', 'other', 'way', 'it', 'is', 'just', 'not', 'a', 'bank', 'fraud', 'but', 'has', 'all', 'the', 'ingrediants', 'of', 'a', 'massive', 'scam', 'URL', 'breaking', 'cnnnews18', 'has', 'accessed', 'complainant', 'letter', 'to', 'pmo', 'on', 'nirav', 'modi', 'complainant', 'received', 'acknowledgment', 'from', 'pmo', 'over', 'letter', 'in', 'USER_MENTION', 'with', 'details', 'bigbankscam']]\n"
     ]
    }
   ],
   "source": [
    "data_tweet = data_tweet.values.tolist()\n",
    "for i in range(0,len(data_tweet)):\n",
    "    data_tweet[i] = data_tweet[i].split()\n",
    "    \n",
    "print(data_tweet[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "max_tweet_size = 0\n",
    "for i in data_tweet:\n",
    "    if(len(i)>max_tweet_size):\n",
    "        max_tweet_size = len(i)\n",
    "        \n",
    "print(max_tweet_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = stopwords.words('english') + list(string.punctuation) + ['will', 'also', 'said','a','URL','USER_MENTION']\n",
    "tweets_after_stop_words=[]\n",
    "for i in data_tweet:\n",
    "    tweet = []\n",
    "    for j in i:\n",
    "        if(j not in stopset):\n",
    "            tweet.append(j)\n",
    "    tweets_after_stop_words.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,vocab_size, hidden_size,input_size):\n",
    "        super(Net,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.word_embeddings = nn.Embedding(vocab_size+106,100)\n",
    "        self.GRU = nn.GRU(100,self.hidden_size, batch_first = True)\n",
    "        self.linear = nn.Linear(self.hidden_size, 24)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self,x_input,hidden_state):\n",
    "        embedded = self.word_embeddings(x_input)\n",
    "        #print(embedded.shape)\n",
    "        #output = embedded.view(-1,-1, self.hidden_size)\n",
    "        output, hn = self.GRU(embedded)\n",
    "        #hn_ = hn[0].reshape(x_input.shape[0],output.shape[1]*output.shape[2])\n",
    "        #print(output.shape)\n",
    "        linear = self.linear(hn[0])\n",
    "        #print(linear.shape)\n",
    "        class_labels = self.softmax(linear)\n",
    "        \n",
    "        return class_labels\n",
    "\n",
    "    def H_t0(self, batch_size):\n",
    "        return torch.zeros(1,batch_size,self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_pd = data_pd['Issue']\n",
    "stance_pd = data_pd['Stance']\n",
    "\n",
    "all_words = tweets\n",
    "word2cnt = Counter(all_words)\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issue_vocab(issues,want = 'issue2id'):\n",
    "    if(want == 'issue2id'):\n",
    "        issue2idx = {issue:idx for idx,issue in enumerate(issues)}\n",
    "        return issue2idx\n",
    "    \n",
    "    else:\n",
    "        idx2issue = {idx:issue for idx,issue in enumerate(issues)}\n",
    "        return idx2issue\n",
    "    \n",
    "def sent_vocab(want = 'sent2id'):\n",
    "    sent2id = {'Disagreement':0,'Neutral':1,'Agreement':2}\n",
    "    id2sent = {0:'Disagreement',1:'Neutral',2:'Agreement'}\n",
    "    if(want == 'sent2id'):\n",
    "        return sent2id\n",
    "\n",
    "    else:\n",
    "        #idx2issue = {idx:issue for idx,issue in enumerate(issues)}\n",
    "        return idx2sent\n",
    "\n",
    "def load_vocab():\n",
    "    load_words = open(\"vocab_real.csv\").readlines()\n",
    "    for i in range(len(load_words)):\n",
    "        load_words[i] = load_words[i].split(',')\n",
    "    vocab = [load_words[i][0] for i in range(len(load_words))]\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    idx2word = {idx: word for idx, word in enumerate(vocab)}\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(tweets, issue_, sentiments,issues):\n",
    "    #print(len(tweets))\n",
    "    stop_words = ['the','of','in','and','a','is','on','this','all','it','will','for','to','be','with',\n",
    "              'at','are','u','has','that','by','from', 'as','was','have','its','an','if','been','be','also','should','which']\n",
    "    max_tweet_size = 120\n",
    "    word2idx,idx2word = load_vocab()\n",
    "    issue2idx = issue_vocab(issues,'issue2id')\n",
    "    sent2idx = sent_vocab()\n",
    "\n",
    "    x_tweet, y_issue, y_label = [], [], []\n",
    "    for tweet,issue,sent in zip(tweets, issue_, sentiments):\n",
    "        x = [word2idx.get(word, 1) for word in (tweet + u\" </S>\").split() if word not in stop_words]\n",
    "        x = np.array(x)\n",
    "        t = np.zeros(max_tweet_size)\n",
    "        if len(x)<=max_tweet_size:\n",
    "            t[:len(x)] = x\n",
    "        else:\n",
    "            t = x[:max_tweet_size]\n",
    "\n",
    "        #print(issue)\n",
    "        y_i = [issue2idx.get(issue,1)]\n",
    "        y_l = [sent2idx.get(sent,1)]\n",
    "\n",
    "        x_tweet.append(t)\n",
    "        y_issue.append(y_i)\n",
    "        y_label.append(y_l)\n",
    "    #print(len(x_tweet))\n",
    "    return np.array(x_tweet), np.array(y_issue), np.array(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches_train(data_x,data_y,batch_size, idx):\n",
    "    start =  batch_size*idx\n",
    "    end = start + batch_size\n",
    "    if(end>len(data_x)):\n",
    "        return data_x[start:], data_y[start:]\n",
    "    return data_x[start:end], data_y[start:end]\n",
    "\n",
    "def batches_test(data_x,data_y,batch_size, idx):\n",
    "    start =  batch_size*idx\n",
    "    end = start + batch_size\n",
    "    return data_x[start:end], data_y[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_issues = 24#len(issues)\n",
    "epochs = 10\n",
    "input_size = 100\n",
    "vocab_size = len(word_counts)\n",
    "output_size_issue = num_issues\n",
    "output_size_label = 3\n",
    "hidden_size = 256\n",
    "batch_size = 32\n",
    "#n_iters = int(len(x_train)/batch_size)\n",
    "lr = 0.01\n",
    "\n",
    "num_issues = len(issues_pd.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss_all_issues = defaultdict(list)\n",
    "metrics_dict = defaultdict(list)\n",
    "predicted_list = defaultdict(list)\n",
    "ground_truth = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5753 1439 7192\n"
     ]
    }
   ],
   "source": [
    "num_train = int(0.8*len(tweets))\n",
    "num_test = len(tweets)-num_train\n",
    "\n",
    "print(num_train,num_test,num_train+num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bedanta/ml/lib/python3.5/site-packages/ipykernel_launcher.py:45: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "net = Net(vocab_size, hidden_size,100)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adagrad(net.parameters(),lr=0.1)\n",
    "\n",
    "# data_withot_one_issue = data_pd[data_pd.Issue != one]\n",
    "# data_with_the_issue = data_pd[data_pd.Issue == one]\n",
    "\n",
    "# data_list_with = data_withot_one_issue.values\n",
    "# data_list_without = data_with_the_issue.values\n",
    "data_pd_values = data_pd.values\n",
    "\n",
    "tweets_train = data_pd_values[:num_train,0]\n",
    "#print(tweets_train[0])\n",
    "issue_train = data_pd_values[:num_train,3]\n",
    "label_train = data_pd_values[:num_train,4]\n",
    "\n",
    "tweets_test = data_pd_values[num_train:num_train+num_test,0]\n",
    "issue_test = data_pd_values[num_train:num_train+num_test,3]\n",
    "label_test = data_pd_values[num_train:num_train+num_test,4]\n",
    "\n",
    "x_tweet_train,y_issue_train, y_label_train = create_data(tweets_train,issue_train,label_train,issues)\n",
    "#print(x_tweet_train[0])\n",
    "x_tweet_test,y_issue_test, y_label_test = create_data(tweets_test,issue_test,label_test,issues)\n",
    "x_tweet_test, y_label_test = Variable(torch.LongTensor(x_tweet_test)), Variable(torch.LongTensor(y_label_test))\n",
    "#print(x_tweet_test)\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "epoch_losses = []\n",
    "for e in range(0,10):\n",
    "    epoch_loss = 0\n",
    "    for idx in range(0,int(len(x_tweet_train)/batch_size)+1):\n",
    "        #net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        batch_x, batch_y = batches_train(x_tweet_train,y_issue_train,batch_size,idx)\n",
    "        batch_x = Variable(torch.LongTensor(batch_x))\n",
    "        batch_y = Variable(torch.LongTensor(batch_y))\n",
    "        batch_y = batch_y.reshape(batch_y.shape[0])\n",
    "        encoder_hidden = Variable(net.H_t0(batch_y.shape[0]))\n",
    "        output = net(batch_x,encoder_hidden)\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.data[0]\n",
    "    epoch_loss /= len(x_tweet_train)/batch_size\n",
    "    epoch_losses.append(epoch_loss)\n",
    "\n",
    "encoder_hidden_test = Variable(net.H_t0(len(x_tweet_test)))\n",
    "predicted_output = net(x_tweet_test,encoder_hidden_test)\n",
    "predicted_output = predicted_output.reshape(len(x_tweet_test),24)\n",
    "predicted_output = predicted_output.detach().numpy()\n",
    "predicted_output = np.argmax(predicted_output,axis = 1)\n",
    "#predicted_list[one] = predicted_output\n",
    "#ground_truth[one] = y_label_test\n",
    "accuracy = accuracy_score(predicted_output,y_label_test)\n",
    "print(accuracy)\n",
    "plt.plot(epoch_losses)\n",
    "plt.show()\n",
    "#epoch_loss_all_issues[one] = epoch_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_hidden_test = Variable(net.H_t0(len(x_tweet_test)))\n",
    "# predicted_output = net(x_tweet_test,encoder_hidden_test)\n",
    "# predicted_output = predicted_output.reshape(len(x_tweet_test),24)\n",
    "# predicted_output = predicted_output.detach().numpy()\n",
    "# predicted_output = np.argmax(predicted_output,axis = 1)\n",
    "# #predicted_list[one] = predicted_output\n",
    "# #ground_truth[one] = y_label_test\n",
    "# accuracy = accuracy_score(predicted_output,y_label_test)\n",
    "# print(accuracy)\n",
    "# plt.plot(epoch_losses)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 8, ..., 8, 8, 8])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
